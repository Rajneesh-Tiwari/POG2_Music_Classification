{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cd1d1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-13T22:07:08.725227Z",
     "iopub.status.busy": "2022-03-13T22:07:08.723535Z",
     "iopub.status.idle": "2022-03-13T22:07:12.476152Z",
     "shell.execute_reply": "2022-03-13T22:07:12.475433Z",
     "shell.execute_reply.started": "2022-03-13T21:30:10.356204Z"
    },
    "papermill": {
     "duration": 3.780887,
     "end_time": "2022-03-13T22:07:12.476357",
     "exception": false,
     "start_time": "2022-03-13T22:07:08.695470",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import torchaudio\n",
    "import librosa\n",
    "from nnAudio.features.cqt import CQT1992v2\n",
    "from scipy.signal import tukey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ac190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    apex=False\n",
    "    debug=False\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name='tf_efficientnet_b7_ns'\n",
    "    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    epochs=3\n",
    "    #factor=0.2 # ReduceLROnPlateau\n",
    "    #patience=4 # ReduceLROnPlateau\n",
    "    #eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=3 # CosineAnnealingLR\n",
    "    #T_0=3 # CosineAnnealingWarmRestarts\n",
    "    lr=1e-4\n",
    "    min_lr=1e-6\n",
    "    batch_size=48\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    qtransform_params={\"hop_length\": 1024, \"n_bins\": 64,'fmax':None}    \n",
    "    seed=42\n",
    "    target_size=1\n",
    "    target_col='target'\n",
    "    n_fold=5\n",
    "    trn_fold=[0] # [0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    grad_cam=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555d024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T22:07:12.524391Z",
     "iopub.status.busy": "2022-03-13T22:07:12.523651Z",
     "iopub.status.idle": "2022-03-13T22:07:12.583307Z",
     "shell.execute_reply": "2022-03-13T22:07:12.582851Z",
     "shell.execute_reply.started": "2022-03-13T19:39:18.337501Z"
    },
    "papermill": {
     "duration": 0.085451,
     "end_time": "2022-03-13T22:07:12.583427",
     "exception": false,
     "start_time": "2022-03-13T22:07:12.497976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\Kaggle\\Pog_Music_Classification/train.csv')\n",
    "df_test = pd.read_csv(r'C:\\Users\\Kaggle\\Pog_Music_Classification/test.csv')\n",
    "submission = pd.read_csv(r'C:\\Users\\Kaggle\\Pog_Music_Classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956619e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T22:07:12.630375Z",
     "iopub.status.busy": "2022-03-13T22:07:12.629617Z",
     "iopub.status.idle": "2022-03-13T22:07:12.631565Z",
     "shell.execute_reply": "2022-03-13T22:07:12.631935Z",
     "shell.execute_reply.started": "2022-03-13T19:39:18.423524Z"
    },
    "papermill": {
     "duration": 0.02696,
     "end_time": "2022-03-13T22:07:12.632057",
     "exception": false,
     "start_time": "2022-03-13T22:07:12.605097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = Path('C:/Users/Kaggle/Pog_Music_Classification/train/')\n",
    "test_path = Path('C:/Users/Kaggle/Pog_Music_Classification/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925d653",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_train.shape,df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad290c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "valid_filenames = []\n",
    "for i in glob.glob(r'C:/Users/Kaggle/Pog_Music_Classification/resampled_16k/train/*.npy'):\n",
    "    fnames = (i.split('\\\\')[1])\n",
    "    valid_filenames.append(fnames.split('.')[0]+'.ogg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "valid_filenames_test = []\n",
    "for i in glob.glob(r'C:/Users/Kaggle/Pog_Music_Classification/resampled_16k/test/*.npy'):\n",
    "    fnames = (i.split('\\\\')[1])\n",
    "    valid_filenames_test.append(fnames.split('.')[0]+'.ogg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37261605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['filename'].isin(valid_filenames)].reset_index(drop=True)\n",
    "df_test_valid = df_test[df_test['filename'].isin(valid_filenames_test)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some files giving exception in cqt\n",
    "df_train = df_train[df_train['song_id']!=17400].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7253f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_train.shape,df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898f0c4",
   "metadata": {},
   "source": [
    "### Upsample minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7505a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['genre_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtremeMinority = [18]\n",
    "SomeMinority = [17]\n",
    "LowMinority = [14,15,16]\n",
    "\n",
    "# df_train = pd.concat([df_train,df_train[df_train['genre_id'].isin(ExtremeMinority)].sample(n=37,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "# df_train = pd.concat([df_train,df_train[df_train['genre_id'].isin(SomeMinority)].sample(n=42,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "# df_train = pd.concat([df_train,df_train[df_train['genre_id'].isin(LowMinority)].sample(n=50,replace=True,random_state=42)],0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f03f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()#,df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b52f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['genre_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2175ae",
   "metadata": {},
   "source": [
    "#### condense bottom 8 classes into single class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a101c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['genre_id'] = df_train['genre_id'].apply(lambda x: 5 if x>=5 else x).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bce840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['genre_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486306be",
   "metadata": {},
   "source": [
    "### Create Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fold'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9334d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "N_folds = 5\n",
    "kf = StratifiedKFold(5,random_state=42,shuffle=True)\n",
    "fld = 0\n",
    "for i,(_,val_id) in enumerate(kf.split(df_train['filename'],df_train['genre_id'])):\n",
    "    df_train.loc[val_id,'fold'] = int(fld)\n",
    "    fld += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70943e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6502855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce078a4",
   "metadata": {},
   "source": [
    "#### Channel wise max: 2.7517, 2.7950"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a3ce9",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ba0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import Compose\n",
    "import torchvision\n",
    "\n",
    "tfms = Compose(\n",
    "        [torchvision.transforms.CenterCrop((256,576))])\n",
    "#     [torchvision.transforms.Resize((128,960))])\n",
    "#     [torchvision.transforms.CenterCrop((128,1152))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.rand((28,28,16,16))\n",
    "# y = torch.zeros(384, 384)\n",
    "# i = j = 27\n",
    "# y[i*16:(i+1)*16, j*16:(j+1)*16].shape,a[1,19].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POGFiles(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df, \n",
    "                 train = True,\n",
    "                 transform=tfms,\n",
    "\n",
    "                ):\n",
    "        \n",
    "        \n",
    "        self.df = df\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def load_file(self, filename):\n",
    "        if self.train:\n",
    "            spec = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/spec/448_160/train/{filename}')\n",
    "        else:\n",
    "            spec = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/spec/448_160/test/{filename}')\n",
    "            \n",
    "        return spec\n",
    "\n",
    "\n",
    "#     def inv_stem(self,x):\n",
    "#         x1 = x.view(24,48,16,8)\n",
    "#         y = torch.zeros(384, 384, dtype=x.dtype)\n",
    "#         for i in range(24):\n",
    "#             for j in range(48):\n",
    "#                 y[i*16:(i+1)*16, j*8:(j+1)*8] = x1[i, j]\n",
    "#         return y\n",
    "\n",
    "    def inv_stem(self,x):\n",
    "        x1 = x.transpose(0,1).contiguous().view(24,24,16,16)\n",
    "        y = torch.zeros(384, 384, dtype=x.dtype)\n",
    "        for i in range(24):\n",
    "            for j in range(24):\n",
    "                y[i*16:(i+1)*16, j*16:(j+1)*16] = x1[i, j]\n",
    "        return y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row  = self.df.iloc[index]\n",
    "        \n",
    "        samples = self.load_file(row.filename.split('.')[0]+'.npy')\n",
    "        samples = torch.from_numpy(samples).float()\n",
    "        if self.transform is not None:\n",
    "            samples = self.transform(samples)\n",
    "                    \n",
    "        samples = self.inv_stem(samples).unsqueeze(0)\n",
    "        \n",
    "        if self.train:\n",
    "            label = torch.tensor(row.genre_id,dtype=torch.long)\n",
    "            return samples, label\n",
    "        else:\n",
    "\n",
    "            return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d3428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b = next(iter(POGFiles(df_train,transform=tfms)))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28*28*16*16,196*1024,384*384,24*24*16*16,256*576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 196*1024/(16*16*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22728551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '000000.npy'\n",
    "# a = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/spec/448_448_160/train/{filename}')\n",
    "# b = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/spec/448_160/train/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f319a",
   "metadata": {},
   "source": [
    "#### AST: https://github.com/YuanGongND/ast/blob/master/src/models/ast_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3e71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCLASS = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edcf131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "timm.list_models()\n",
    "# timm.create_model('deit_base_patch16_384',in_chans=1,pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe13664",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.create_model('deit_base_patch16_384',in_chans=1,pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCLASS = df_train['genre_id'].nunique()\n",
    "NCLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa5a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    oof = df_train.copy()\n",
    "    oversampleTrain = False\n",
    "    for fold_num in [0,1,2,3,4]:\n",
    "        print('*****************************************')\n",
    "        print(f'Training Fold {fold_num}')\n",
    "        print('*****************************************')\n",
    "\n",
    "    #with IPyExperimentsPytorch() as exp:\n",
    "        kernel_type = 'deit_base_patch16_384_MonoSpec_Hop512_Mels128'\n",
    "        OUTPUT_DIR = f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/'\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.makedirs(OUTPUT_DIR)\n",
    "            \n",
    "        crit = CrossEntropyLossFlat() #BiTemperedLogisticLoss()#CrossEntropyLossFlat() #LabelSmoothingCrossEntropy(0.025) #CrossEntropyLossFlat() #FocalLoss()\n",
    "        batch_size = 32\n",
    "        n_epochs = 50\n",
    "\n",
    "        training_fold = df_train.query(f'fold!={fold_num}').reset_index(drop=True, inplace=False)\n",
    "        \n",
    "        if oversampleTrain:\n",
    "            print('--------- Oversampling training dataset -----------')\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(ExtremeMinority)].sample(n=150,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(SomeMinority)].sample(n=150,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(LowMinority)].sample(n=100,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "                \n",
    "        train_ds = POGFiles(training_fold,\n",
    "                            transform=tfms\n",
    "                           )\n",
    "\n",
    "        validation_fold = df_train.query(f'fold=={fold_num}').reset_index(drop=True, inplace=False)\n",
    "        valid_ds = POGFiles(validation_fold,\n",
    "                            transform=tfms)\n",
    "\n",
    "        print(f'- Training samples: {len(train_ds)}\\n- Validation Samples : {len(valid_ds)}')\n",
    "\n",
    "        bs = batch_size\n",
    "        train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, num_workers=0,pin_memory=False)\n",
    "        valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs, num_workers=0,shuffle=False,pin_memory=False)\n",
    "\n",
    "        dls = DataLoaders(train_dl, valid_dl)\n",
    "        \n",
    "        \n",
    "        model = timm.create_model('deit_base_patch16_384', pretrained=False, in_chans=1)#get_model(resnet34)\n",
    "        model.head = nn.Linear(768,NCLASS)\n",
    "    \n",
    "        f1_score = F1Score(average=\"micro\")\n",
    "        ### MixUp() in callbacks\n",
    "#         opt = ranger\n",
    "        opt = Adam\n",
    "        learn = Learner(dls, model,opt_func=opt,loss_func=crit,metrics=[f1_score],cbs=[\n",
    "            SaveModelCallback('f1_score', every_epoch=True),\n",
    "                       CSVLogger(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/{fold_num}logs.csv')]).to_fp16()\n",
    "        \n",
    "        learn.fit_one_cycle(n_epochs)\n",
    "\n",
    "#         learn.fit_flat_cos(n_epochs, 1e-2,wd=1e-3)\n",
    "        learn.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}')\n",
    "        learn = learn.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}')\n",
    "        \n",
    "        learn.model.eval()\n",
    "        test_df = df_test\n",
    "        test_ds = POGFiles(df_test_valid,\n",
    "                           transform=tfms,\n",
    "                           train=False\n",
    "                           )\n",
    "\n",
    "        test_ds.input_path = Path(test_path)\n",
    "\n",
    "        bs = batch_size\n",
    "        test_dl = torch.utils.data.DataLoader(test_ds, batch_size=bs, num_workers=0, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "        for xb  in progress_bar(test_dl):\n",
    "            with torch.no_grad():output = learn.model(xb.cuda())\n",
    "            probs.append(torch.softmax(output.float(),1).squeeze().cpu())\n",
    "            preds.append(torch.argmax(output.float(),1).squeeze().cpu())\n",
    "        \n",
    "        oof_ = []\n",
    "        for xb,_  in progress_bar(valid_dl):\n",
    "            with torch.no_grad():output = learn.model(xb.cuda())\n",
    "            oof_.append(torch.softmax(output.float(),1).squeeze().cpu())\n",
    "        \n",
    "        oof_ = [t.detach().numpy() for t in oof_]\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/test_fold_{fold_num}_probs.npy',np.array(probs))\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_probs.npy',oof_)\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_fnames.npy',np.array(validation_fold.song_id))        \n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        sample_df = df_test_valid.copy()\n",
    "        sample_df['target'] = preds\n",
    "        sample_df.to_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}.csv', index=False)\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f002f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400087b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb66133",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2006bc",
   "metadata": {},
   "source": [
    "#### Prog resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa7e37",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import Compose\n",
    "import torchvision\n",
    "\n",
    "tfms = Compose(\n",
    "#     [torchvision.transforms.Resize((160,1072))])\n",
    "    [torchvision.transforms.CenterCrop((160,1072))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_audiomentations as tA\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return tA.Compose(\n",
    "                transforms=[\n",
    "#                      tA.ShuffleChannels(p=0.1,mode=\"per_example\",p_mode=\"per_example\", sample_rate= 16000),\n",
    "                    tA.PeakNormalization(p=0.5,apply_to='only_too_loud_sounds',mode=\"per_example\",p_mode=\"per_example\",sample_rate=16000),\n",
    "#                     tA.BandPassFilter(),\n",
    "                    tA.TimeInversion(p=0.5,p_mode=\"per_example\",sample_rate=16000),\n",
    "#                     tA.PitchShift()\n",
    "#                      tA.AddColoredNoise(p=0.1,mode=\"per_channel\",p_mode=\"per_channel\", sample_rate=16000,max_snr_in_db = 15),\n",
    "                     tA.Shift(p=0.5,mode=\"per_example\",p_mode=\"per_example\", sample_rate=16000,\n",
    "                              max_shift=0.025, min_shift=-0.025),\n",
    "                ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return tA.Compose([\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POGFiles(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df, \n",
    "                 train = True,\n",
    "                 augmentations = None,\n",
    "                 normalize=False,\n",
    "                 ch0Max=2.7517,\n",
    "                 ch1Max=2.7950,\n",
    "                 HOP_LEN = 1024,\n",
    "                 N_FFT=1024,\n",
    "                 n_mels=224,\n",
    "                 transform=tfms,\n",
    "                 audiotfms=None,\n",
    "                 applyTukey=False,\n",
    "                 quantizeData=False,\n",
    "                 MakeThreeChannel= False,\n",
    "                 bins_per_octave = 24,\n",
    "                 n_bins = 64\n",
    "                ):\n",
    "        \n",
    "        \n",
    "        self.df = df\n",
    "        self.train = train\n",
    "        self.ch0Max = ch0Max\n",
    "        self.ch1Max = ch1Max        \n",
    "        self.N_FFT = N_FFT\n",
    "        self.n_bins = n_bins\n",
    "        self.bins_per_octave = bins_per_octave\n",
    "        self.HOP_LEN = HOP_LEN\n",
    "        self.transform = transform\n",
    "        self.n_mels= n_mels\n",
    "        self.audiotfms = audiotfms\n",
    "        self.normalize = normalize\n",
    "        self.MakeThreeChannel = MakeThreeChannel\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def load_file(self, filename):\n",
    "        if self.train:\n",
    "            spec = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/spec/448_160/train/{filename}')\n",
    "        else:\n",
    "            spec = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/spec/448_160/test/{filename}')\n",
    "            \n",
    "        return spec\n",
    "\n",
    "\n",
    "    def inv_stem(self,x):\n",
    "        x1 = x.view(24, 20, 16, 16)\n",
    "        y = torch.zeros(384, 384, dtype=x.dtype)\n",
    "        for i in range(24):\n",
    "            for j in range(20):\n",
    "                y[i*16:(i+1)*16, j*16:(j+1)*16] = x1[i, j]\n",
    "        return y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row  = self.df.iloc[index]\n",
    "        \n",
    "        samples = self.load_file(row.filename.split('.')[0]+'.npy')\n",
    "        samples = torch.from_numpy(samples).float()\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            samples = self.transform(samples)\n",
    "        \n",
    "#         samples = self.inv_stem(samples).unsqueeze(0)\n",
    "        \n",
    "        if self.train:\n",
    "            label = torch.tensor(row.genre_id,dtype=torch.long)\n",
    "            return samples, label\n",
    "        else:\n",
    "\n",
    "            return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0706cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = next(iter(POGFiles(df_train,transform=tfms)))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runProgResize():\n",
    "    oof = df_train.copy()\n",
    "    oversampleTrain = False\n",
    "    for fold_num in [0,1,2,3,4]:\n",
    "        print('*****************************************')\n",
    "        print(f'Training Fold {fold_num}')\n",
    "        print('*****************************************')\n",
    "\n",
    "    #with IPyExperimentsPytorch() as exp:\n",
    "        kernel_type = 'resnext50d_32x4d_MonoSpec_Hop448_Mels160'\n",
    "        kernel_type_prev = 'resnext50d_32x4d_MonoSpec_Hop512_Mels128'\n",
    "        OUTPUT_DIR = f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/'\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "            \n",
    "        crit = CrossEntropyLossFlat() #BiTemperedLogisticLoss()#CrossEntropyLossFlat() #LabelSmoothingCrossEntropy(0.025) #CrossEntropyLossFlat() #FocalLoss()\n",
    "        batch_size = 24\n",
    "        n_epochs = 15\n",
    "\n",
    "        training_fold = df_train.query(f'fold!={fold_num}').reset_index(drop=True, inplace=False)\n",
    "        \n",
    "        if oversampleTrain:\n",
    "            print('--------- Oversampling training dataset -----------')\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(ExtremeMinority)].sample(n=150,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(SomeMinority)].sample(n=150,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(LowMinority)].sample(n=100,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "                \n",
    "        train_ds = POGFiles(training_fold,\n",
    "                            transform=tfms\n",
    "                           )\n",
    "\n",
    "        validation_fold = df_train.query(f'fold=={fold_num}').reset_index(drop=True, inplace=False)\n",
    "        valid_ds = POGFiles(validation_fold,\n",
    "                            transform=tfms)\n",
    "\n",
    "        print(f'- Training samples: {len(train_ds)}\\n- Validation Samples : {len(valid_ds)}')\n",
    "\n",
    "        bs = batch_size\n",
    "        train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, num_workers=0,pin_memory=False)\n",
    "        valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs*2, num_workers=0,shuffle=False,pin_memory=False)\n",
    "\n",
    "        dls = DataLoaders(train_dl, valid_dl)\n",
    "        \n",
    "        \n",
    "        model = timm.create_model('resnext50d_32x4d',in_chans=1,pretrained=False)\n",
    "        model.conv1[0].stride = (1,1)\n",
    "        model.fc = nn.Linear(2048,NCLASS)\n",
    "    \n",
    "    \n",
    "        f1_score = F1Score(average=\"micro\")\n",
    "        \n",
    "        opt = ranger\n",
    "        learn = Learner(dls, model,opt_func=opt,loss_func=crit,metrics=[f1_score],cbs=[MixUp(0.2),SaveModelCallback('f1_score', every_epoch=True),\n",
    "                       CSVLogger(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/{fold_num}logs.csv')]).to_fp16()\n",
    "        \n",
    "                \n",
    "        weights = torch.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type_prev}/fold_{fold_num}.pth')['model']\n",
    "        learn.model.load_state_dict(weights,strict=False)\n",
    "        \n",
    "        learn.fit_flat_cos(n_epochs, 1e-2,wd=1e-3)\n",
    "        learn.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}')\n",
    "        learn = learn.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}')\n",
    "        \n",
    "        learn.model.eval()\n",
    "        test_df = df_test\n",
    "        test_ds = POGFiles(df_test_valid,\n",
    "                           transform=tfms,\n",
    "                           train=False\n",
    "                           )\n",
    "\n",
    "        test_ds.input_path = Path(test_path)\n",
    "\n",
    "        bs = batch_size\n",
    "        test_dl = torch.utils.data.DataLoader(test_ds, batch_size=bs*2, num_workers=0, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "        for xb  in progress_bar(test_dl):\n",
    "            with torch.no_grad():output = learn.model(xb.cuda())\n",
    "            probs.append(torch.softmax(output.float(),1).squeeze().cpu())\n",
    "            preds.append(torch.argmax(output.float(),1).squeeze().cpu())\n",
    "        \n",
    "        oof_ = []\n",
    "        for xb,_  in progress_bar(valid_dl):\n",
    "            with torch.no_grad():output = learn.model(xb.cuda())\n",
    "            oof_.append(torch.softmax(output.float(),1).squeeze().cpu())\n",
    "        \n",
    "        oof_ = [t.detach().numpy() for t in oof_]\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/test_fold_{fold_num}_probs.npy',np.array(probs))\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_probs.npy',oof_)\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_fnames.npy',np.array(validation_fold.song_id))        \n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        sample_df = df_test_valid.copy()\n",
    "        sample_df['target'] = preds\n",
    "        sample_df.to_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ded9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    runProgResize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73985967",
   "metadata": {},
   "outputs": [],
   "source": [
    "del _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Finetune even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runProgResizeTune():\n",
    "    oof = df_train.copy()\n",
    "    oversampleTrain = False\n",
    "    for fold_num in [0,1,2,3,4]:\n",
    "        print('*****************************************')\n",
    "        print(f'Training Fold {fold_num}')\n",
    "        print('*****************************************')\n",
    "\n",
    "    #with IPyExperimentsPytorch() as exp:\n",
    "        kernel_type = 'ecaresnext50t_32x4d_MonoSpec_Hop448_Mels160_FTUNE'\n",
    "        kernel_type_prev = 'ecaresnext50t_32x4d_MonoSpec_Hop448_Mels160'\n",
    "        OUTPUT_DIR = f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/'\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "            \n",
    "        crit = CrossEntropyLossFlat() #BiTemperedLogisticLoss()#CrossEntropyLossFlat() #LabelSmoothingCrossEntropy(0.025) #CrossEntropyLossFlat() #FocalLoss()\n",
    "        batch_size = 32\n",
    "        n_epochs = 5\n",
    "\n",
    "        training_fold = df_train.query(f'fold!={fold_num}').reset_index(drop=True, inplace=False)\n",
    "        \n",
    "        if oversampleTrain:\n",
    "            print('--------- Oversampling training dataset -----------')\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(ExtremeMinority)].sample(n=150,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(SomeMinority)].sample(n=150,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "            training_fold = pd.concat([training_fold,training_fold[training_fold['genre_id'].isin(LowMinority)].sample(n=100,replace=True,random_state=42)],0).reset_index(drop=True)\n",
    "                \n",
    "        train_ds = POGFiles(training_fold,\n",
    "                            transform=tfms\n",
    "                           )\n",
    "\n",
    "        validation_fold = df_train.query(f'fold=={fold_num}').reset_index(drop=True, inplace=False)\n",
    "        valid_ds = POGFiles(validation_fold,\n",
    "                            transform=tfms)\n",
    "\n",
    "        print(f'- Training samples: {len(train_ds)}\\n- Validation Samples : {len(valid_ds)}')\n",
    "\n",
    "        bs = batch_size\n",
    "        train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, num_workers=0,pin_memory=False)\n",
    "        valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs*2, num_workers=0,shuffle=False,pin_memory=False)\n",
    "\n",
    "        dls = DataLoaders(train_dl, valid_dl)\n",
    "        \n",
    "        \n",
    "        model = timm.create_model('ecaresnext50t_32x4d',in_chans=1,pretrained=False)\n",
    "        model.conv1[0].stride = (1,1)\n",
    "        model.fc = nn.Linear(2048,NCLASS)\n",
    "    \n",
    "    \n",
    "        f1_score = F1Score(average=\"micro\")\n",
    "        fname = f'{kernel_type}_{fold_num}'\n",
    "        opt = ranger\n",
    "        learn = Learner(dls, model,opt_func=opt,loss_func=crit,metrics=[f1_score],\n",
    "                        model_dir = Path(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/{fold_num}'),\n",
    "                        cbs=[MixUp(0.1),SaveModelCallback('f1_score',fname=fname, comp=np.greater),\n",
    "                         CSVLogger(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/{fold_num}logs.csv')]).to_fp16()\n",
    "        \n",
    "                \n",
    "        weights = torch.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type_prev}/fold_{fold_num}.pth')['model']\n",
    "        learn.model.load_state_dict(weights,strict=False)\n",
    "        \n",
    "        learn.fit_one_cycle(n_epochs, 1e-4,wd=1e-3)\n",
    "        learn.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}')\n",
    "        learn = learn.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}')\n",
    "        \n",
    "        learn.model.eval()\n",
    "        test_df = df_test\n",
    "        test_ds = POGFiles(df_test_valid,\n",
    "                           transform=tfms,\n",
    "                           train=False\n",
    "                           )\n",
    "\n",
    "        test_ds.input_path = Path(test_path)\n",
    "\n",
    "        bs = batch_size\n",
    "        test_dl = torch.utils.data.DataLoader(test_ds, batch_size=bs*2, num_workers=0, shuffle=False)\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "        for xb  in progress_bar(test_dl):\n",
    "            with torch.no_grad():output = learn.model(xb.cuda())\n",
    "            probs.append(torch.softmax(output.float(),1).squeeze().cpu())\n",
    "            preds.append(torch.argmax(output.float(),1).squeeze().cpu())\n",
    "        \n",
    "        oof_ = []\n",
    "        for xb,_  in progress_bar(valid_dl):\n",
    "            with torch.no_grad():output = learn.model(xb.cuda())\n",
    "            oof_.append(torch.softmax(output.float(),1).squeeze().cpu())\n",
    "        \n",
    "        oof_ = [t.detach().numpy() for t in oof_]\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/test_fold_{fold_num}_probs.npy',np.array(probs))\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_probs.npy',oof_)\n",
    "        np.save(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_fnames.npy',np.array(validation_fold.song_id))        \n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        sample_df = df_test_valid.copy()\n",
    "        sample_df['target'] = preds\n",
    "        sample_df.to_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fold_num}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1664ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    runProgResizeTune()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd46d87",
   "metadata": {},
   "source": [
    "### OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ecaresnext50t_32x4d_MonoSpec_Hop448_Mels160'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715259de",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOFOut = pd.DataFrame()\n",
    "for fld in range(5):\n",
    "    fold_num = fld\n",
    "    kernel_type= 'ecaresnext50t_32x4d_MonoSpec_Hop448_Mels160'\n",
    "    OOF = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_probs.npy',allow_pickle=True)\n",
    "    ID = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_fnames.npy',allow_pickle=True)\n",
    "    OOF = ([item for sublist in OOF for item in sublist])\n",
    "    OOF = pd.DataFrame(OOF)\n",
    "    OOF['ID'] = ID\n",
    "    OOFOut = pd.concat([OOF,OOFOut],0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOFOut['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOFOut.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ac9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOFOut = pd.merge(OOFOut,df_train[['song_id','genre_id']],left_on='ID',right_on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOFOut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc4253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OOFOut['genre_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab06257",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_preds=OOFOut.iloc[:,:19].idxmax(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a591816",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(OOFOut['genre_id'],OOF_preds,average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(OOF_preds,OOFOut['genre_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c6e01",
   "metadata": {},
   "source": [
    "### Mode based sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b153fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d470c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = submission.copy().drop('genre_id',1)\n",
    "for fld in range(5):\n",
    "    fname = pd.read_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/fold_{fld}.csv')\n",
    "    out = pd.merge(out,fname[['song_id','target']],on='song_id',how='left')\n",
    "    \n",
    "submission['genre_id']=out.drop('song_id',1).mode(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a51537",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission['song_id']==22612,'genre_id'] = 1\n",
    "submission.loc[submission['song_id']==24013,'genre_id'] = 0\n",
    "submission['genre_id'] = submission['genre_id'].astype(int)\n",
    "submission.to_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/5Fold_mode.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd8c37",
   "metadata": {},
   "source": [
    "### Mode based sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e4d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = submission.copy().drop('genre_id',1)\n",
    "for fld in range(5):\n",
    "    for kernels in ['resnest50d_MonoSpec_Hop448_Mels160_FTune',\n",
    "                    'resnest50d_MonoSpec_Hop448_Mels160',\n",
    "                    ]:\n",
    "        fname = pd.read_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernels}/fold_{fld}.csv')\n",
    "        out = pd.merge(out,fname[['song_id','target']],on='song_id',how='left')\n",
    "    \n",
    "submission['genre_id']=out.drop('song_id',1).mode(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16987ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission['song_id']==22612,'genre_id'] = 1\n",
    "submission.loc[submission['song_id']==24013,'genre_id'] = 0\n",
    "submission['genre_id'] = submission['genre_id'].astype(int)\n",
    "submission.to_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/5Fold_mode_ens_2bestmodels.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb2f14f",
   "metadata": {},
   "source": [
    "### Mode based sub: check OOF Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e16ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "out = pd.DataFrame()\n",
    "for kernels in [\n",
    "                'eb1_MonoSpec_Hop448_Mels160',\n",
    "                'resnest50d_MonoSpec_Hop448_Mels160_FTune',\n",
    "#                 'resnest50d_MonoSpec_Hop448_Mels160',\n",
    "#                 'resnet50d_MIXUP_finetune_MonoSpec_Hop512_Mels128',\n",
    "#                 'tf_efficientnet_b1_MonoSpec_Hop512_Mels128',\n",
    "#                 'densenet121d_MonoSpec_Hop448_Mels160',\n",
    "#                 'densenet121d_MonoSpec_Hop448_Mels160_FTUNE',\n",
    "#                 'resnest26d_MonoSpec_Hop448_Mels160_FTUNE',\n",
    "#                 'ecaresnet50t_MonoSpec_Hop448_Mels160_FTUNE',\n",
    "#                 'seresnet50t_MonoSpec_Hop448_Mels160_FTUNE',\n",
    "#                 'ecaresnet50t_MonoSpec_Hop448_Mels160',\n",
    "                'resnest50d_MonoSpec_Hop448_Mels160_NoisyTrain',\n",
    "                'ecaresnext50t_32x4d_MonoSpec_Hop448_Mels160',\n",
    "                'resnext50d_32x4d_MonoSpec_Hop448_Mels160'\n",
    "               ]:\n",
    "    OOFOut = pd.DataFrame()\n",
    "    for fld in range(5):\n",
    "        fold_num = fld\n",
    "        kernel_type= kernels\n",
    "        OOF = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_probs.npy',allow_pickle=True)\n",
    "        ID = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/oof_fold_{fold_num}_fnames.npy',allow_pickle=True)\n",
    "        OOF = ([item for sublist in OOF for item in sublist])\n",
    "        OOF = pd.DataFrame(OOF)\n",
    "        OOF['ID'] = ID\n",
    "        OOFOut = pd.concat([OOF,OOFOut],0).reset_index(drop=True)\n",
    "\n",
    "    OOFOut = pd.merge(OOFOut,df_train[['song_id','genre_id']],left_on='ID',right_on='song_id',how='left')\n",
    "    OOF_preds=OOFOut.iloc[:,:19].idxmax(1)\n",
    "    out = pd.concat([out,OOF_preds],1)\n",
    "    out['genre_id'] = OOFOut['genre_id']\n",
    "    \n",
    "out['preds'] = out.drop('genre_id',1).mode(1)[0].astype(int)\n",
    "f1_score(out['genre_id'],out['preds'],average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49bb80d",
   "metadata": {},
   "source": [
    "### Mode based sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type ='ecaresnext50t_32x4d_MonoSpec_Hop448_Mels160'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = submission.copy().drop('genre_id',1)\n",
    "for fld in range(5):\n",
    "    for kernels in ['resnest50d_MonoSpec_Hop448_Mels160_FTune',\n",
    "                    'resnest50d_MonoSpec_Hop448_Mels160',\n",
    "                    'resnet50d_MIXUP_finetune_MonoSpec_Hop512_Mels128',\n",
    "                    'tf_efficientnet_b1_MonoSpec_Hop512_Mels128',\n",
    "                    'ecaresnext50t_32x4d_MonoSpec_Hop448_Mels160',\n",
    "                    'eb1_MonoSpec_Hop448_Mels160'\n",
    "                    ]:\n",
    "        fname = pd.read_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernels}/fold_{fld}.csv')\n",
    "        out = pd.merge(out,fname[['song_id','target']],on='song_id',how='left')\n",
    "    \n",
    "submission['genre_id']=out.drop('song_id',1).mode(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9228b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission['song_id']==22612,'genre_id'] = 1\n",
    "submission.loc[submission['song_id']==24013,'genre_id'] = 0\n",
    "submission['genre_id'] = submission['genre_id'].astype(int)\n",
    "submission.to_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type}/5Fold_mode_ens_6bestmodels.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aee9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38e4a3",
   "metadata": {},
   "source": [
    "### PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05682cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type_upd = 'resnet50d_MIXUP_finetune_MonoSpec_Hop512_Mels128' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = pd.read_csv(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type_upd}/fold_{fld}.csv')\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a31427",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out = pd.DataFrame(np.zeros((5076,19)))\n",
    "for fld in range(5):\n",
    "    probs = np.load(f'C:/Users/Kaggle/Pog_Music_Classification/outputs/{kernel_type_upd}/test_fold_{fld}_probs.npy',allow_pickle=True)\n",
    "    p = pd.DataFrame([item.numpy().ravel() for sublist in probs for item in sublist])\n",
    "    preds_out += p.values/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d7f3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46196141",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out['song_id'] = fname['song_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fba0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out[(preds_out.iloc[:,:19].values > 0.85).sum(1)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL = preds_out[(preds_out.iloc[:,:19].values > 0.85).sum(1)>0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51abfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL.to_csv(r'C:\\Users\\Kaggle\\Pog_Music_Classification\\outputs\\resnet50d_MIXUP_finetune_MonoSpec_Hop512_Mels128\\PL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60daefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(PL.iloc[:,:-1].values,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83961eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14319dab",
   "metadata": {},
   "source": [
    "### End ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
